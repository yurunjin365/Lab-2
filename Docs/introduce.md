赛题简介
本次新人赛是Datawhale与天池联合发起的0基础入门系列赛事第五场 —— 零基础入门推荐系统之新闻推荐场景下的用户行为预测挑战赛。

赛题以新闻APP中的新闻推荐为背景，要求选手根据用户历史浏览点击新闻文章的数据信息预测用户未来点击行为，即用户的最后一次点击的新闻文章，测试集对最后一次点击行为进行了剔除。通过这道赛题来引导大家了解推荐系统中的一些业务背景，解决实际问题，帮助竞赛新人进行自我练习、自我提高。

为了更好的引导大家入门，还特别为本赛题定制了学习方案，其中包括推荐系统基础、通用流程和baseline方案学习三部分。通过对本方案的完整学习，可以帮助掌握推荐系统相关竞赛的基本技能。同时平台也将提供专属的视频直播学习通道，敬请关注平台通告。

新人赛的目的主要是为了更好地带动处于初学者阶段的新同学们一起玩起来，因此，我们鼓励所有选手，基于赛题发表notebook分享，内容包含但不限于对赛题的理解、数据分析及可视化、算法模型的分析以及一些核心的思路等内容。

# 代码规范

选手需要提交训练好的模型，以及能够针对初赛B榜测试集产出预测结果的训练、预测代码。所有文件请打包在zip压缩包内，对提交文件的组织形式要求如下：

1、原始数据文件夹 tcdata/

选手无需提交天池提供的竞赛数据文件，我们会把提供的所有原始文件（与官网上的文件和文件名一致）放到tcdata/文件夹下。需要注意，初始的时候tcdata文件夹会被清空，然后再放入原始数据文件。

数据结构示例如下：
```
|-- tcdata
    |--train_click_log.csv
    |--articles.csv
    |--articles_emb.csv
    |--testB_click_log.csv
```

2、用户数据文件夹 user_data/

选手训练好的模型、预测过程中需要生成的中间数据，请放入该文件夹中。文件夹下的子目录、文件名，选手可自行决定。

数据结构示例如下：
```
|-- user_data
    |-- model_data
        |-- model.dat
    |-- tmp_data
        |-- tmp.dat
    |-- 计算的中间文件
    |-- 临时存储目录
```

3、预测结果输出文件夹 prediction_result/

选手提交的代码，需要在此文件夹中产出针对B榜测试集的预测结果。预测结果文件的格式与竞赛中的提交要求一致，结果文件请命名为result.csv。初始的时候prediction_result/文件夹会被清空。

数据结构如下：
```
|-- prediction_result
    |-- result.csv
```

4、代码文件夹 code/

选手需要在此文件夹中存放预测与训练代码。代码审核会剔除有作弊行为、方案中无算法贡献的团队。参赛选手的模型要求可复现，复现偏差小于规定范围。

a. 预测相关

请确保对初赛B榜测试集的预测结果可以由提交的代码产出，训练与预测流程所使用到的源码都要包含在提交的文件中，并在README.md文件中指导运行。

所使用的依赖（操作系统版本，MATLAB/Python的版本，需要安装的Python package，使用到的PyTorch，TensorFlow，MXNet的版本等）都需要在README文件中写明。

如果有需要编译的文件，请提供编译的脚本，并在README.md中说明编译所需的GCC、CUDA、CuDNN版本等依赖。

请提供`test.sh`文件作为程序入口，确保可以通过执行该文件来运行预测程序，得到最终结果，并将结果保存到上述的`prediction_result/result.csv`文件中。

读入文件的路径请使用相对路径，比如 `../tcdata/XX`

b. 训练相关

请将训练相关代码也存放于此代码文件夹中，文件结构组织由选手自行决定，并在下述README.md文件中简略叙述训练流程并给出训练脚本。

请固定训练时时的超参, 例如学习率、batchsize等影响模型训练的参数。

如果对训练集进行了补充标注、数据增广等，下述README.md文件中说明，并给出增广代码与标注结果。

5、解决方案及算法介绍文件 README.md

请选手在README.md文件中介绍自己的解决方案及算法，并叙述模型训练复现流程。若选手提交的代码在运行时有需要特殊注意的内容，也请在该文件中一并说明

所使用的系统依赖（操作系统版本，Python/Matlab的版本）都需要在README.md文件中写明。如果使用Python环境，需提供requirements.txt以确保运行环境可复现 (Python package的版本依赖, 例如PyTorch，TensorFlow，MXNet、numpy等)。

6、附注

a）提交代码文件夹结构举例
```
project
    |--README.md            # 解决方案及算法介绍文件，必选
    |--requirements.txt     # Python环境依赖
    |--tcdata
    |--user_data
        |--model_data       # 模型文件夹示例，可自行组织
            |--model.dat
        |--tmp_data         # 临时存储文件夹示例，可自行组织
            |--tmp.dat
    |--prediction_result
    |--code
        |--train            # 训练代码文件夹示例，可自行组织
        |--test             # 预测代码文件夹示例，可自行组织
        |--test.sh			# 预测执行脚本，必选
        |--train.sh			# 训练示例脚本，可自行取舍
```

b）模型大小超过2G

如果模型大小超出2G，可以通过提交入口内的STS超大文件上传功能进行上传。

# 赛题：零基础入门推荐系统 - 新闻推荐

## 1. 赛题背景
本赛题以新闻 APP 中的用户交互数据为背景，要求参赛选手根据用户历史的点击行为，预测用户未来最可能点击的新闻文章。这不仅是一个经典的点击率预测（CTR）或 Top-N 推荐问题，更是理解推荐系统全链路（召回、排序、重排）的绝佳入门实践。

## 2. 赛题目标
*   任务类型：类目预测 / 序列推荐
*   输入：用户历史点击日志、新闻文章属性信息。
*   输出：为测试集中的每个用户推荐 5 篇他们最可能点击的文章。

## 3. 数据描述
赛题数据来源于某新闻 APP 平台的用户交互日志。数据经过脱敏处理，主要包含以下两张表：

### 3.1 用户点击日志表 (`train_click_log.csv` / `testA_click_log.csv`)
记录了用户点击文章的行为日志。

| 字段名 | 描述 | 示例 |
| :--- | :--- | :--- |
| `user_id` | 用户的唯一标识 | 10001 |
| `article_id` | 文章的唯一标识 | 23456 |
| `click_time` | 点击时间戳（脱敏后） | 1500000000 |
| `click_environment` | 点击环境（如 Wi-Fi、4G 等） | 1 |
| `click_deviceGroup` | 点击设备组 | 1 |
| `click_os` | 点击操作系统 | 2 |
| `click_country` | 点击城市/国家 | 1 |
| `click_region` | 点击地区 | 20 |
| `click_referrer_type` | 点击来源类型 | 1 |

### 3.2 文章属性表 (`articles.csv`)
记录了文章的元数据信息。

| 字段名 | 描述 | 示例 |
| :--- | :--- | :--- |
| `article_id` | 文章的唯一标识 | 23456 |
| `category_id` | 文章所属的一级类别 | 3 |
| `created_at_ts` | 文章创建时间戳 | 1499999999 |
| `words_count` | 文章字数 | 156 |

### 3.3 数据嵌入 (`articles_emb.csv`)
为了方便选手使用深度学习模型，赛题方通常还会提供文章的 Embedding 向量（通常基于 Word2Vec 或 BERT 训练得到），用于表征文章的语义信息。

## 4. 评价指标
本赛题采用 MRR (Mean Reciprocal Rank, 平均倒数排名) 作为线上评价指标。

$$ MRR = \frac{1}{|Q|} \sum_{i=1}^{|Q|} \frac{1}{rank_i} $$

*   |Q|：测试集用户总数。
*   rank_i：对于第 $i$ 个用户，真实点击的文章在推荐列表中的排名位置。
    *   如果推荐列表是 `[A, B, C, D, E]`，用户真实点击了 `C`，则 $rank = 3$，倒数排名为 $1/3$。
    *   如果真实点击的文章不在推荐列表中，则该用户的得分为 0。

解读：MRR 对排名的敏感度很高。把用户真正感兴趣的物品排在越前面，得分越高。

## 5. 解题思路 (Baseline)

针对此类推荐问题，通常采用经典的 “召回 (Recall) -> 排序 (Ranking)” 两阶段策略：

### 第一阶段：召回 (Recall)
目标是从海量文章中快速筛选出用户可能感兴趣的一小部分候选集（例如 50-100 篇）。
*   规则策略：热门文章召回、近期文章召回。
*   协同过滤 (CF)：
    *   UserCF：推荐相似用户点击过的文章。
    *   ItemCF：推荐与用户历史点击文章相似的文章（基于共现矩阵）。
*   向量召回：利用 `articles_emb` 计算文章间的余弦相似度进行召回。
*   图算法：构建 用户-文章 二部图，使用 DeepWalk 或 Node2Vec 游走产生序列嵌入。

### 第二阶段：排序 (Ranking)
目标是对召回的候选集进行精细化打分排序，选出 Top 5。
*   特征工程：
    *   用户特征：活跃度、偏好类别、点击时间统计。
    *   文章特征：热度、字数、创建时间、被点击趋势。
    *   交互特征：用户-文章类别的交叉统计、用户过去是否点击过同类文章。
*   模型选择：
    *   LGBM / XGBoost：经典的树模型，处理表格特征能力强，适合入门。
    *   DeepFM / DIN：深度学习模型，能更好地处理稀疏特征和序列特征。

### 第三阶段：模型融合 (Ensemble)
*   对不同模型（如 ItemCF 的结果 + LGBM 的结果）进行加权融合，通常能显著提升 MRR 分数。

## 6. 提交格式
提交文件应为 `csv` 格式，包含 `user_id` 和 `article_id` 两列。对于每个用户，推荐 5 个文章 ID，用逗号分隔（实际上通常是一行一个用户，推荐列表需自行处理成符合要求的格式，具体参考赛题提交示例）。

```csv
user_id,article_id
10001, 234, 567, 890, 123, 456
10002, ...
```