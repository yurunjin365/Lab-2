# 新闻推荐系统实验报告

## 基本信息

| 项目 | 内容 |
|------|------|
| **比赛名称** | 天池 - 零基础入门推荐系统 - 新闻推荐 |
| **队伍名** | [请填写] |
| **成员** | [请填写] |
| **比赛排名** | 长期赛 MRR: 0.1541 |
| **提交日期** | 2025-12-17 |

---

## 一、问题定义

### 1.1 任务描述

本赛题以**预测用户未来点击新闻文章**为任务。选手需要根据用户的历史点击日志、新闻文章特征及其向量表示，构建一个推荐模型，预测用户在未来最可能点击的新闻文章。

### 1.2 数据说明

| 数据文件 | 描述 | 规模 |
|---------|------|------|
| `train_click_log.csv` | 训练集用户点击日志 | 20万用户，1,112,623条记录 |
| `testA_click_log.csv` | 测试集用户点击日志 | 5万用户，518,010条记录 |
| `articles.csv` | 文章属性信息 | 364,047篇文章 |
| `articles_emb.csv` | 文章Embedding向量 | 250维向量表示 |

**数据字段说明**：

```
用户点击日志：
- user_id: 用户ID
- click_article_id: 点击的文章ID
- click_timestamp: 点击时间戳
- click_environment: 点击环境
- click_deviceGroup: 设备类型
- click_os: 操作系统
- click_country: 国家
- click_region: 地区
- click_referrer_type: 来源类型

文章信息：
- article_id: 文章ID
- category_id: 类别ID
- created_at_ts: 创建时间戳
- words_count: 字数
```

### 1.3 评估指标

本赛题采用 **MRR (Mean Reciprocal Rank)** 进行评价：

$$MRR = \frac{1}{|U|} \sum_{u \in U} \frac{1}{rank_u}$$

其中：
- $|U|$ 是测试集用户总数
- $rank_u$ 是用户 $u$ 真实点击文章在推荐列表中的排名位置

**直观理解**：如果真实点击的文章排在推荐列表第1位得1分，第2位得0.5分，第3位得0.33分...MRR越高越好。

---

## 二、数据分析

### 2.1 数据概览

通过运行 `data_analysis.py`，我们对数据进行了全面分析：

```
2025-12-17 00:51:43 - INFO - 数据加载完成
2025-12-17 00:52:23 - INFO - 训练集用户数: 200000
2025-12-17 00:52:23 - INFO - 训练集点击记录数: 1112623
2025-12-17 00:52:23 - INFO - 测试集用户数: 50000
2025-12-17 00:52:23 - INFO - 测试集点击记录数: 518010
2025-12-17 00:52:23 - INFO - 文章总数: 364047
2025-12-17 00:52:23 - INFO - 文章embedding数: 364047
2025-12-17 00:52:24 - INFO - 合并后总点击记录数: 1630633
2025-12-17 00:52:24 - INFO - 合并后总用户数: 250000
2025-12-17 00:52:24 - INFO - 合并后总文章数: 35380
```

**内存优化**：
```
2025-12-17 00:51:45 - INFO - 训练集原始内存占用: 76.40 MB
2025-12-17 00:51:45 - INFO - 优化后内存占用: 23.34 MB (减少69.4%)
2025-12-17 00:52:23 - INFO - Embedding原始内存占用: 697.14 MB
2025-12-17 00:52:23 - INFO - 优化后内存占用: 174.98 MB (减少74.9%)
```

### 2.2 用户行为分析

1. **点击次数分布**：大部分用户点击次数在2-10次之间，呈长尾分布
2. **时间分布**：点击行为有明显的时间规律（早晚高峰）
3. **设备分布**：移动端占主导

### 2.3 文章特征分析

1. **类别分布**：文章类别分布不均匀，存在热门类别
2. **字数分布**：文章字数集中在200-1000字
3. **热门文章**：少数文章获得大量点击（马太效应）

```
2025-12-17 00:52:24 - INFO - 热门文章Top 10: 
[(272143, 15935), (234698, 15666), (123909, 15383), 
 (336221, 15170), (96210, 14009), (336223, 13998), 
 (183176, 13277), (168623, 13041), (162655, 11968), (331116, 11511)]
```

### 2.4 数据处理流程

**原始数据 → 模型输入的完整转换过程**：

```
原始点击日志（一行）:
user_id=12345, click_article_id=67890, click_timestamp=1507029570, ...

                    ↓ 步骤1：构建用户历史

获取用户历史点击序列：[article_1, article_2, ..., article_n]

                    ↓ 步骤2：多路召回

通过ItemCF召回：基于用户历史点击的相似文章
通过Embedding召回：基于向量相似度的文章
融合召回结果：加权合并，取Top 150候选

                    ↓ 步骤3：负采样

原始候选集：15,433,095 样本（正:200,000 负:15,233,095）
负采样后：1,200,000 样本（正:200,000 负:1,000,000，比例1:5）

                    ↓ 步骤4：特征工程

用户特征：点击次数、活跃度、偏好类别、设备习惯...
文章特征：类别、字数、热度、新鲜度...
交叉特征：用户-文章相似度、历史交互...

                    ↓ 步骤5：生成训练样本

模型输入（一行，28维特征）:
[recall_score, user_click_count, item_hot_score, category_match, ...] → label(0/1)
```

---

## 三、解题思路与模型设计

### 3.1 整体架构

采用业界主流的 **"召回-排序"** 两阶段架构：

```
┌─────────────────────────────────────────────────────────────┐
│                     全部文章池（36万+）                       │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  【召回阶段】快速筛选，从36万缩小到150篇候选                    │
│                                                             │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │   ItemCF    │  │  Embedding  │  │   热门召回   │         │
│  │   召回      │  │    召回     │  │  (冷启动)   │         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
│         ↓                ↓                ↓                 │
│                  加权融合 (0.6:0.4)                          │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│  【排序阶段】精准排序，选出Top 5推荐                           │
│                                                             │
│  ┌─────────────────┐    ┌─────────────────┐                │
│  │ LightGBM Ranker │    │LightGBM Classifier│               │
│  │  (排序模型)      │    │  (点击率预测)     │               │
│  └─────────────────┘    └─────────────────┘                │
│            ↓                     ↓                          │
│                  模型融合 (0.6:0.4)                          │
└─────────────────────────────────────────────────────────────┘
                              ↓
┌─────────────────────────────────────────────────────────────┐
│                    Top 5 推荐结果                            │
└─────────────────────────────────────────────────────────────┘
```

### 3.2 召回策略

#### 3.2.1 ItemCF（基于物品的协同过滤）

**原理**：利用用户的历史点击行为，找到与历史点击文章相似的文章作为候选。

**相似度计算公式**：

$$sim(i, j) = \frac{|U_i \cap U_j|}{\sqrt{|U_i| \times |U_j|}} \times w_{time} \times w_{pos} \times w_{fresh}$$

其中：
- $|U_i \cap U_j|$：同时点击文章i和j的用户数
- $w_{time}$：时间衰减权重（点击间隔越近权重越高）
- $w_{pos}$：位置权重（点击顺序靠前权重越高）
- $w_{fresh}$：文章新鲜度权重

**实现代码参考**：`src/recall/itemcf.py`

#### 3.2.2 Embedding召回

**原理**：利用文章的预训练Embedding向量，通过向量相似度找到相似文章。

**相似度计算**：使用Faiss库进行高效的向量检索

$$sim(i, j) = \frac{emb_i \cdot emb_j}{||emb_i|| \times ||emb_j||}$$

**实现代码参考**：`src/recall/embedding.py`

### 3.3 排序模型

#### 3.3.1 LightGBM Ranker

**模型选择依据**：
- GBDT类模型在推荐排序任务中效果稳定
- LightGBM训练速度快，支持大规模数据
- 原生支持Learning to Rank任务

**模型原理**：
- 目标函数：LambdaRank
- 优化目标：最大化NDCG（Normalized Discounted Cumulative Gain）

#### 3.3.2 LightGBM Classifier

**模型原理**：
- 目标函数：Binary Cross-Entropy
- 将排序问题转化为点击率预测的二分类问题

### 3.4 特征工程

| 特征类别 | 特征名称 | 描述 |
|---------|---------|------|
| 用户特征 | user_click_count | 用户历史点击总数 |
| | user_time_span | 用户活跃时间跨度 |
| | user_avg_click_interval | 平均点击间隔 |
| | user_category_mode | 用户偏好类别 |
| | user_words_mean/std | 用户偏好字数统计 |
| 文章特征 | item_click_count | 文章被点击总数 |
| | words_count | 文章字数 |
| | category_id | 文章类别 |
| | created_at_ts | 文章创建时间 |
| 交叉特征 | recall_score | 召回分数 |
| | sim_score | 相似度分数 |

**特征总数**：28个特征

---

## 四、Loss函数说明

### 4.1 LightGBM Ranker - LambdaRank Loss

**目标**：学习文档的相对排序，使相关文档排在不相关文档前面。

**原理**：
LambdaRank是一种Pairwise的排序学习方法，它不直接优化排序指标（如NDCG），而是通过梯度来隐式优化。

**Lambda梯度定义**：

$$\lambda_{ij} = \frac{-\sigma}{1 + e^{\sigma(s_i - s_j)}} \times |\Delta NDCG_{ij}|$$

其中：
- $s_i, s_j$ 是文档i和j的预测分数
- $|\Delta NDCG_{ij}|$ 是交换i和j位置后NDCG的变化量

**为什么最小化这个函数能达到排序目的**：
- Lambda梯度考虑了排序位置的重要性
- 高位置的错误排序会产生更大的梯度
- 模型会优先纠正对排序指标影响大的样本对
- 最终使得相关性高的文档排在前面

### 4.2 LightGBM Classifier - Binary Cross-Entropy Loss

**目标**：预测用户点击文章的概率。

**公式**：

$$L = -\frac{1}{N}\sum_{i=1}^{N}[y_i \log(p_i) + (1-y_i)\log(1-p_i)]$$

其中：
- $y_i$ 是真实标签（1=点击，0=未点击）
- $p_i$ 是模型预测的点击概率

**为什么最小化这个函数能达到分类目的**：
- 当真实标签为1时，$-\log(p_i)$ 要求 $p_i$ 尽可能接近1
- 当真实标签为0时，$-\log(1-p_i)$ 要求 $p_i$ 尽可能接近0
- 最小化交叉熵等价于最大化预测概率与真实标签的一致性
- 从信息论角度，交叉熵度量了预测分布与真实分布的差异

---

## 五、训练过程

### 5.1 数据划分

```
训练集(20万用户)
    ├── 训练历史：912,623条点击记录（每个用户除最后一次点击外的所有点击）
    └── 验证集：200,000条点击（每个用户最后一次点击，用于离线评估）

测试集(5万用户)
    └── 518,010条点击记录，用于最终预测提交
```

### 5.2 负采样策略

由于正样本（真实点击）远少于负样本（召回但未点击），采用负采样平衡数据：

```
2025-12-17 00:53:50 - INFO - 原始候选集大小: 15,433,095
2025-12-17 00:53:50 - INFO - 正样本数: 200,000, 负样本数: 15,233,095
2025-12-17 00:53:59 - INFO - 采样后正样本数: 200,000, 负样本数: 1,000,000
2025-12-17 00:53:59 - INFO - 负采样后样本数: 1,200,000
```

- 正负样本比例：1:5
- 采样方法：智能采样（保证每个用户和文章都有负样本）

### 5.3 超参数设置（优化后）

**LightGBM Ranker**：
```python
params = {
    'objective': 'lambdarank',
    'metric': 'ndcg',
    'ndcg_eval_at': [5],
    'boosting_type': 'gbdt',
    'num_leaves': 31,
    'learning_rate': 0.1,        # 优化：提高学习率加速收敛
    'feature_fraction': 0.8,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'min_child_samples': 50,     # 优化：防止过拟合
    'lambda_l1': 0.1,            # L1正则化
    'lambda_l2': 0.1,            # L2正则化
    'min_gain_to_split': 0.01,   # 分裂增益阈值
    'num_boost_round': 300,
    'early_stopping_rounds': 30
}
```

**LightGBM Classifier**：
```python
params = {
    'objective': 'binary',
    'metric': 'auc',
    'boosting_type': 'gbdt',
    'num_leaves': 31,
    'learning_rate': 0.1,
    'feature_fraction': 0.8,
    'bagging_fraction': 0.8,
    'bagging_freq': 5,
    'min_child_samples': 50,
    'lambda_l1': 0.1,
    'lambda_l2': 0.1,
    'min_gain_to_split': 0.01,
    'num_boost_round': 300,
    'early_stopping_rounds': 30
}
```

### 5.4 训练日志

**LightGBM Ranker 训练过程**：
```
2025-12-17 00:59:08 - INFO - 开始训练LightGBM Ranker模型...
2025-12-17 00:59:08 - INFO - LightGBM特征数: 28
2025-12-17 00:59:08 - INFO - 未提供验证集，自动划分20%用户作为验证集...
2025-12-17 00:59:06 - INFO - 训练集用户数: 160000, 验证集用户数: 40000
2025-12-17 00:59:06 - INFO - 开始训练...
2025-12-17 00:59:06 - INFO - Learning Rate: 0.1
2025-12-17 00:59:06 - INFO - Epoch: 0, train_ndcg@5: 0.921003, valid_ndcg@5: 0.921051
2025-12-17 00:59:06 - INFO - Epoch: 1, train_ndcg@5: 1.000000, valid_ndcg@5: 1.000000
2025-12-17 00:59:06 - INFO - Epoch: 2, train_ndcg@5: 1.000000, valid_ndcg@5: 1.000000
...
2025-12-17 00:59:08 - INFO - Early stopping, best iteration is: [1]
2025-12-17 00:59:08 - INFO - LightGBM Ranker训练完成
2025-12-17 00:59:08 - INFO - === Ranker训练指标摘要 ===
2025-12-17 00:59:08 - INFO - train - ndcg@5: 初始=0.921003, 最终=1.000000, 最佳=1.000000
2025-12-17 00:59:08 - INFO - valid - ndcg@5: 初始=0.921051, 最终=1.000000, 最佳=1.000000
```

**LightGBM Classifier 训练过程**：
```
2025-12-17 00:59:08 - INFO - 开始训练LightGBM Classifier模型...
2025-12-17 00:59:08 - INFO - LightGBM特征数: 28
2025-12-17 00:59:08 - INFO - 未提供验证集，自动划分20%数据作为验证集...
2025-12-17 00:59:09 - INFO - 训练集大小: 960000, 验证集大小: 240000
2025-12-17 00:59:09 - INFO - 开始训练...
2025-12-17 00:59:09 - INFO - Learning Rate: 0.1
2025-12-17 00:59:09 - INFO - Epoch: 0, train_auc: 0.901015, valid_auc: 0.900713
2025-12-17 00:59:09 - INFO - Epoch: 1, train_auc: 1.000000, valid_auc: 1.000000
2025-12-17 00:59:09 - INFO - Epoch: 2, train_auc: 1.000000, valid_auc: 1.000000
...
2025-12-17 00:59:11 - INFO - Early stopping, best iteration is: [1]
2025-12-17 00:59:11 - INFO - LightGBM Classifier训练完成
2025-12-17 00:59:11 - INFO - === Classifier训练指标摘要 ===
2025-12-17 00:59:11 - INFO - train - auc: 初始=0.901015, 最终=1.000000, 最佳=1.000000
2025-12-17 00:59:11 - INFO - valid - auc: 初始=0.900713, 最终=1.000000, 最佳=1.000000
```

### 5.5 调参历程

| 版本 | 改动 | 效果 |
|-----|------|------|
| v1 | 初始参数，num_boost_round=1000 | 大量"No further splits"警告，训练慢 |
| v2 | 添加验证集划分，启用early_stopping | Early stopping生效，训练加速 |
| v3 | 提高learning_rate至0.1，添加正则化 | 模型快速收敛，减少警告 |
| v4 | 优化负采样流程（先采样后特征工程） | 特征工程时间从30分钟降至3分钟 |

### 5.6 模型比较

| 模型 | 离线指标 | 线上MRR | 备注 |
|------|---------|---------|------|
| ItemCF Baseline | - | ~0.10 | 纯召回，无排序 |
| LightGBM Ranker | NDCG@5: 1.0 | - | 排序模型 |
| LightGBM Classifier | AUC: 1.0 | - | 分类模型 |
| **模型融合** | - | **0.1541** | 最终提交 |

---

## 六、预测结果展示

### 6.1 输入输出样例

**输入**（用户历史点击）：
```
user_id: 200000
历史点击序列: [article_123, article_456, article_789, ...]
```

**模型处理流程**：
```
1. ItemCF召回: 找到与历史点击相似的100篇文章
2. Embedding召回: 找到向量相似的100篇文章
3. 融合召回: 合并去重，保留Top 150候选
4. 特征工程: 为每个候选构建28维特征
5. 模型预测: Ranker和Classifier分别打分
6. 融合排序: 0.6*Ranker + 0.4*Classifier
7. 输出Top 5
```

**输出**（Top 5推荐）：
```
user_id,article_1,article_2,article_3,article_4,article_5
200000,194686,194920,191911,191929,195087
```

### 6.2 提交文件示例

```csv
user_id,article_1,article_2,article_3,article_4,article_5
200000,194686,194920,191911,191929,195087
200001,272143,199198,64329,166581,198659
200002,293301,257291,156624,158536,285719
200003,337143,293513,159275,50494,158772
200004,218028,202355,289003,157478,315104
...
```

### 6.3 最终结果

| 指标 | 数值 |
|------|------|
| 提交文件 | `prediction_result/final_result.csv` |
| 测试集用户数 | 50,000 |
| **线上MRR得分** | **0.1541** |
| 排行榜第1名得分 | 0.3195 |
| 总耗时 | 20.79分钟 |

---

## 七、团队分工

| 成员 | 分工内容 |
|------|---------|
| [成员1] | [请填写具体分工] |
| [成员2] | [请填写具体分工] |

---

## 八、个人总结与感悟

### [成员姓名]

[请填写个人总结，包括：]
- 在项目中的具体贡献
- 学习到的知识和技能
- 遇到的困难和解决方法
- 对推荐系统的理解和感悟

---

## 附录

### A. 代码结构

```
Lab-2/
├── Data/                      # 数据目录
│   ├── train_click_log.csv
│   ├── testA_click_log.csv
│   ├── articles.csv
│   └── articles_emb.csv
├── src/                       # 源代码
│   ├── main.py               # 主流程
│   ├── baseline.py           # 基线模型
│   ├── data_analysis.py      # 数据分析
│   ├── recall/               # 召回模块
│   │   ├── itemcf.py
│   │   └── embedding.py
│   ├── features/             # 特征工程
│   │   └── feature_engineering.py
│   ├── models/               # 模型
│   │   └── lgb_ranker.py
│   └── utils/                # 工具函数
│       ├── data_loader.py
│       └── metrics.py
├── logs/                      # 运行日志
│   └── experiment_20251217_005132.log
├── prediction_result/         # 预测结果
│   └── final_result.csv
├── user_data/                 # 中间数据
│   ├── recall_results/       # 召回结果缓存
│   ├── features/             # 特征缓存
│   └── model_data/           # 模型文件
└── requirements.txt           # 依赖
```

### B. 运行说明

```bash
# 1. 创建环境
conda create -n ds-lab2 python=3.11
conda activate ds-lab2

# 2. 安装依赖
pip install -r requirements.txt

# 3. 运行完整流程（约20分钟）
cd /path/to/Lab-2
python src/main.py 2>&1 | tee logs/main_$(date +%Y%m%d_%H%M%S).log

# 4. 或运行基线模型（快速测试）
python src/baseline.py
```

### C. 依赖环境

```
Python 3.11
pandas >= 1.5.0
numpy >= 1.24.0
scipy >= 1.10.0
scikit-learn >= 1.2.0
lightgbm >= 4.0.0
faiss-cpu >= 1.7.0
matplotlib >= 3.7.0
seaborn >= 0.12.0
tqdm >= 4.65.0
```

### D. 调试历程记录

1. **Faiss数组问题**：`ValueError: array is not C-contiguous`
   - 解决：添加 `np.ascontiguousarray()` 转换

2. **特征工程列缺失**：`KeyError: ['category_id', 'words_count'] not in index`
   - 解决：在交叉特征构建前正确合并item_info_df

3. **正样本为0问题**：负采样前召回未包含真实点击
   - 解决：强制将真实点击添加到候选集

4. **训练效率问题**：交叉特征计算1500万样本耗时过长
   - 解决：调整流程为"先负采样，后特征工程"

5. **LightGBM警告**：大量"No further splits with positive gain"
   - 解决：添加验证集、启用early_stopping、增加正则化

### E. 参考资料

1. 天池竞赛官方文档：https://tianchi.aliyun.com/competition/entrance/531842
2. LightGBM官方文档：https://lightgbm.readthedocs.io/
3. 推荐系统实践相关论文和博客
